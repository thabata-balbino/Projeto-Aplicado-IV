Acesse atrav√©s do link: https://colab.research.google.com/drive/1XPQbErVknRpPupdELOZv98J6z9lb454E?usp=sharing

# ============================================================
# BIBLIOTECAS
# ============================================================

import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

sns.set_style("whitegrid")


# ============================================================
# 1. COLETA DA API
# ============================================================

def fetch_all_data(url, params):
    all_records = []
    offset = 0
    print("Iniciando coleta de dados da API ArcGIS...\n")

    while True:
        params['resultOffset'] = offset
        response = requests.get(url, params=params)
        data = response.json()
        features = data.get('features', [])

        if not features:
            break

        all_records.extend([f['attributes'] for f in features])
        offset += params['resultRecordCount']

        print(f"‚Üí Registros coletados at√© agora: {len(all_records)}")

        if len(features) < params['resultRecordCount']:
            break

    print(f"\nColeta finalizada! Total de registros: {len(all_records)}")
    return pd.DataFrame(all_records)


# ============================================================
# 2. PREPARA√á√ÉO DOS DADOS
# ============================================================

def prepare_data(df):
    df.columns = df.columns.str.lower()

    if 'data' in df.columns:
        df['datetime'] = pd.to_datetime(df['data'], errors='coerce')
    elif 'data_hora' in df.columns:
        df['datetime'] = pd.to_datetime(df['data_hora'], errors='coerce')
    else:
        raise ValueError("Nenhuma coluna de data encontrada (data ou data_hora).")

    df = df.sort_values('datetime').drop_duplicates(subset=['datetime'])
    return df


# ============================================================
# 3. VALORES AUSENTES
# ============================================================

def missing_values_report(df):
    missing = df.isnull().sum()
    perc = (df.isnull().mean() * 100)

    print("\nüìã Relat√≥rio de Valores Ausentes:")
    print(pd.DataFrame({"Faltantes": missing, "%": perc.round(2)}))

    plt.figure(figsize=(12,5))
    perc.sort_values(ascending=False).plot(kind='bar')
    plt.title("Percentual de valores ausentes por coluna")
    plt.ylabel("%")
    plt.show()


# ============================================================
# 4. LIMPEZA
# ============================================================

def clean_data(df, threshold=0.20):
    df = df.loc[:, df.isnull().mean() < threshold]
    df = df.dropna(subset=['datetime'])
    return df


# ============================================================
# 5. EDA COMPLETA
# ============================================================

def eda_completa(df):

    print("\n==============================")
    print("FORMATO DA COLUNA DATA")
    print("==============================")
    print(df['datetime'].head())
    print("Tipo:", df['datetime'].dtype)

    # Poluentes dispon√≠veis
    poluentes = ['pm2_5', 'no2', 'o3']
    poluentes = [p for p in poluentes if p in df.columns]

    # Estat√≠stica descritiva
    print("\n==============================")
    print("ESTAT√çSTICA DESCRITIVA DOS POLUENTES")
    print("==============================")

    desc = df[poluentes].agg(["mean", "median", "std"]).T
    print(desc)

    plt.figure(figsize=(8,3))
    sns.heatmap(desc, annot=True, cmap="Blues", fmt=".2f")
    plt.title("Estat√≠stica Descritiva ‚Äî PM2.5, NO2 e O3")
    plt.show()

    # Histogramas
    print("\n==============================")
    print("DISTRIBUI√á√ÉO DOS POLUENTES")
    print("==============================")

    for p in poluentes:
        plt.figure(figsize=(7,4))
        sns.histplot(df[p], kde=True)
        plt.title(f"Distribui√ß√£o de {p.upper()}")
        plt.show()

    # Boxplots
    print("\n==============================")
    print("OUTLIERS ‚Äì BOXPLOTS")
    print("==============================")

    for p in poluentes:
        plt.figure(figsize=(7,4))
        sns.boxplot(x=df[p])
        plt.title(f"Boxplot de {p.upper()}")
        plt.show()

    # Correla√ß√£o
    print("\n==============================")
    print("CORRELA√á√ÉO ENTRE POLUENTES")
    print("==============================")

    if len(poluentes) >= 2:
        corr = df[poluentes].corr()
        print(corr)

        plt.figure(figsize=(6,4))
        sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
        plt.title("Correla√ß√£o")
        plt.show()


# ============================================================
# 6. COMPARA√á√ÉO COM A OMS
# ============================================================

def compare_with_limits(df, limite_pm25=15):
    df['date'] = df['datetime'].dt.date
    df_diario = df.groupby('date')['pm2_5'].mean().reset_index()
    df_diario['acima_limite'] = df_diario['pm2_5'] > limite_pm25

    perc = df_diario['acima_limite'].mean() * 100
    print(f"\nüìä Dias acima do limite da OMS (PM2.5 > 15 ¬µg/m¬≥): {perc:.2f}%")

    return df_diario


# ============================================================
# 7. SALVAR RESULTADOS
# ============================================================

def save_results(df_diario):
    df_diario.to_csv("analise_pm25_diario.csv", index=False)
    print("\nArquivo salvo: analise_pm25_diario.csv")


# ============================================================
# 8. PIPELINE COMPLETO
# ============================================================

def main_pipeline(url, params):
    df = fetch_all_data(url, params)
    df = prepare_data(df)
    missing_values_report(df)
    df = clean_data(df)
    eda_completa(df)

    if 'pm2_5' in df.columns:
        df_diario = compare_with_limits(df)
        save_results(df_diario)
    else:
        print("‚ö†Ô∏è Coluna 'pm2_5' n√£o encontrada para compara√ß√£o de limites.")

    print("\n‚úÖ Pipeline finalizado com sucesso!")
    return df


# ============================================================
# 9. MODELO BASE ‚Äì REGRESS√ÉO LINEAR
# ============================================================

def modelo_base(df):
    print("\nTreinando modelo base (Regress√£o Linear para PM2.5)...")

    variaveis_possiveis = ['temp', 'ur', 'vel_vento', 'o3', 'no2']
    variaveis = [v for v in variaveis_possiveis if v in df.columns]

    print("Vari√°veis dispon√≠veis para o modelo:", variaveis)

    df_modelo = df.dropna(subset=['pm2_5'] + variaveis)
    X = df_modelo[variaveis]
    y = df_modelo['pm2_5']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    modelo = LinearRegression()
    modelo.fit(X_train, y_train)

    y_pred = modelo.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)

    print(f"\nüìà Resultados do Modelo Base:")
    print(f"Coeficiente de determina√ß√£o (R¬≤): {r2:.3f}")
    print(f"Erro quadr√°tico m√©dio (MSE): {mse:.2f}")

    # ---------------------------------------------
    # REGRESS√ÉO SOBREPOSTA AOS DADOS
    # ---------------------------------------------

    if "no2" in variaveis:
        plt.figure(figsize=(7,5))

        # scatter dos dados reais
        plt.scatter(df_modelo["no2"], df_modelo["pm2_5"], alpha=0.5, label="Dados")

        # reta ajustada
        x_line = np.linspace(df_modelo["no2"].min(), df_modelo["no2"].max(), 100)
        y_line = modelo.coef_[variaveis.index("no2")] * x_line + modelo.intercept_

        plt.plot(x_line, y_line, color="red", linewidth=2, label="Reta de regress√£o")

        plt.xlabel("NO‚ÇÇ")
        plt.ylabel("PM2.5")
        plt.title("Regress√£o Linear: PM2.5 em fun√ß√£o de NO‚ÇÇ")
        plt.legend()
        plt.show()

    # ---------------------------------------------
    # Gr√°fico real vs previsto
    # ---------------------------------------------
    plt.figure(figsize=(7,5))
    plt.scatter(y_test, y_pred, alpha=0.6)
    plt.xlabel("Valores reais (PM2.5)")
    plt.ylabel("Valores previstos")
    plt.title("Regress√£o Linear ‚Äì Reais vs Previstos")
    plt.plot([y_test.min(), y_test.max()],
             [y_test.min(), y_test.max()], 'r--')
    plt.show()

    # Distribui√ß√£o dos res√≠duos
    residuos = y_test - y_pred
    plt.figure(figsize=(7,5))
    sns.histplot(residuos, kde=True)
    plt.title("Distribui√ß√£o dos res√≠duos")
    plt.xlabel("Res√≠duo")
    plt.show()

    return modelo


# ============================================================
# EXECU√á√ÉO
# ============================================================

url = "https://services1.arcgis.com/OlP4dGNtIcnD3RYf/ArcGIS/rest/services/Qualidade_do_ar_dados_horarios_2011_2018/FeatureServer/3/query"
params = {
    "where": "1=1",
    "outFields": "*",
    "f": "json",
    "resultRecordCount": 2000,
    "resultOffset": 0
}

df = main_pipeline(url, params)
modelo = modelo_base(df)

